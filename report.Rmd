---
title: "Project 2 experiments"
author: "Nicolas Forget"
date: "26/04/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(knitr)
```

## Preliminary tests

In this section, various configuration of the branch-and-bound are tested on each set of instances. The parameters of the algorithm are the followings:

  * node selection. This describes how the algorithm chooses the next node to explore. Two configurations are tested.
    + depth first (`depth`). The last node created is the first node explored.
    + breadth first (`breadth`). The first node created is the first node explored.
    
  * objective branching. This describes how sub-problems are created in the objective space, if any is created. The three configuration from [FORGET20] are tesed.
    + no objective branching (`noOB`). No sub-problems is created in the objective space.
    + cone objective branching (`coneOB`). A unique sub-problem is created, providing upper bounds on the objectives.
    + full objective branching (`fullOB`). As much disjoint sub-problems as possible are created.
   
  * lower bound set computation. This describes how the lower bound set is computed. Two configurations are tested.
    + linear relaxation (`LP`). The linear relaxation is computed from scratch at each node.
    + warmstarted linear relaxation (`WLP`). At a given node, the computation of the linear relaxation is warmstarted using the linear relaxation of its father node.
    
  * variable splitting value selection. Given a branching variable $x_i$, this describes how the algorithm chooses the value to branch on. This parameter is relevant only for problems with integer variables, as one can only branch on 0 and 1 in the binary case.
    + median value (`med`). The median value of $x_i$ among the extreme points is chosen. The purpose behind this rule is to have more balanced tree.
    + most often fractional value (`mofv`). The value $v \in \mathbb{Z}$ is chosen such that the number of extreme points of the lower bound set that have $x_i \in ]v,v+1[$ is the highest. If there is no decimal point, the `med` rule is called. The purpose behind this rule is to discard as much non-integer points as possible in both sub-problems created.
    
Other parameters :

  * variable index selection. This describes how the algorithm chooses the variable to split when performing branching on a node. Here, only one configuration is tested.
    + most often fractional. The variable that is the most often fractional among the extreme points of the lower bound set is chosen. In the binary case, if no variable is fractionnal, the one with the most variability (i.e. the most equally distributed between 0 and 1) is chosen. In the integer case, if no variable is fractional, the first free variable that has at least two different values is chosen. In all other cases, the first free variable is chosen. Same rule as in [FORGET20].


```{r cars, echo=FALSE}
#dat <- read.csv("results.csv")
datPrelim <- read.csv("resultsPrelim.csv")
datMain <- read.csv("resultsMain.csv")

#dat <- dat %>%
#  mutate(pb = strsplit( strsplit(instance, "_")[[1]][1] , "-" )[[1]][2])

datPrelim <- datPrelim %>%
  group_by(instance, configLB, configNodeSel, configOB) %>%
  mutate(pb = strsplit( strsplit(instance, "_")[[1]][1] , "-" )[[1]][2])

datPrelim <- datPrelim %>%
  group_by(instance, configLB, configNodeSel, configOB) %>%
  mutate(cpuTotal = min(cpuTotal,600))

datMain <- datMain %>%
  group_by(instance, configLB, configNodeSel, configOB) %>%
  mutate(pb = strsplit( strsplit(instance, "_")[[1]][1] , "-" )[[1]][2])

datMain <- datMain %>%
  group_by(instance, configLB, configNodeSel, configOB) %>%
  mutate(cpuTotal = min(cpuTotal,3600))
```

### Integer Linear Programs (Kirlik and Sayin, 2014)

This set of instances is extracted from [Kirlik and Sayin (2014)](http://home.ku.edu.tr/~moolibrary/). It consists of randomly generated multi-objective integer linear programs.

There is a plot for each lower bound set configuration (LP, WLP) and number of objectives (3, 4, 5).

```{r, echo = FALSE}
datPrelim %>%
  filter(pb == "ILP") %>%
  group_by(p, configLB, configOB, configNodeSel, configValSplit) %>%
  arrange(cpuTotal) %>%
  mutate(count = row_number()) %>%
    ggplot() +
    geom_step(aes(x = cpuTotal, y = count, color = configOB, linetype = configNodeSel)) +
    facet_grid(vars(p), vars(configLB, configValSplit), scales = "free") +
    xlab("CPU time (in seconds)") + ylab("number of instances solved")


```

### Uncapatitated Facility Location Problem (Forget et. al., 2020)

This set of instances is extracted from [Forget et. al. (2020)](https://github.com/MCDMSociety/MOrepo-Forget20) . Instances for 4 and 5 objectives are generated by following the same rules of generation.

There is a plot for each lower bound set configuration (LP, WLP) and number of objectives (3, 4, 5).

```{r, echo = FALSE}
datPrelim %>%
  filter(pb == "UFLP") %>%
  group_by(p, configLB, configOB, configNodeSel) %>%
  arrange(cpuTotal) %>%
  mutate(count = row_number()) %>%
    ggplot() +
    geom_step(aes(x = cpuTotal, y = count, color = configOB, linetype = configNodeSel)) +
    facet_grid(vars(p), vars(configLB), scales = "free") +
    xlab("CPU time (in seconds)") + ylab("number of instances solved")


```

### Production Planning Problem

This set of instances correspond to production planning problem. It has the following form:

![PPP](ppp_form_2.png){width=35%}

where $c_t^k \in [1,100]$, $h_t^k \in [1,100]$, $f_t^k \in [1,2500]$, $d_t \in [1,50]$, and $M = \sum\limits_{t=1}^T d_t$.

There is a plot for each lower bound set configuration (LP, WLP) and number of objectives (3, 4, 5).

```{r, echo = FALSE}
inter <- datPrelim %>%
  filter(pb == "PPP") %>%
  group_by(p, configLB, configOB, configNodeSel, configValSplit) %>%
  arrange(cpuTotal) %>%
  mutate(cr = row_number()) #%>%
#    ggplot() +
#    geom_step(aes(x = cpuTotal, y = cr, color = configOB, linetype = configNodeSel)) +
#    facet_grid(vars(p), vars(configLB), scales = "free")

inter %>%
  ggplot() +
  geom_step(aes(cpuTotal, cr, color=configOB, linetype=configNodeSel)) +
  facet_grid(vars(p), vars(configLB, configValSplit), scales = "free") +
    xlab("CPU time (in seconds)") + ylab("number of instances solved")

```

### Agregated results

We consider that we have no information regarding the class of the instance.

These are the agregated results that we dicussed last time, but since a new rule on variable value splitting is tested and one of the problem classes (UFLP) is binary, we have a difference in terms of the number of instances solved (UFLP was not solved with med). Thus it gives a weight to PPP and ILP (they are solved twice more and gives it more importance with respect to OB and node selection). So to interpret carefully.

```{r, echo = FALSE}
datPrelim %>%
  group_by(p, configLB, configOB, configNodeSel, configValSplit) %>%
  arrange(cpuTotal) %>%
  mutate(count = row_number()) %>%
    ggplot() +
    geom_step(aes(x = cpuTotal, y = count, color = configOB, linetype = configNodeSel)) +
    facet_grid(vars(p), vars(configLB, configValSplit), scales = "free") +
    xlab("CPU time (in seconds)") + ylab("number of instances solved")


```

From now on, we will stick to breadth first and cone OB for $p = 3$; and breadth first and no OB for $p \geq 3$.

## How beneficial is it to warmstart the computation of the lower bound set?

Given a fixed number of objectives, how does warmstarting the LB set performs compared to computing the LP relax from scratch at each iteration?

There is a plot for each problem (ILP, PPP, UFLP) and number of objectives (3, 4, 5). Only the best configuration in terms of CPU time regarding node selection and objective branching is kept for each instance.

```{r, echo=FALSE}
# from prelim 

tst2 <- datPrelim %>% # tst is best config only LP and WLP for prelim expe
  group_by(instance, configLB, configValSplit) %>%
  mutate(cpu = min(cpuTotal)) %>%
  filter(cpu == cpuTotal) %>%
  mutate(cpt = row_number()) %>%
  filter(cpt == 1)

tst3 <- datPrelim %>%
  filter((p==3 && configOB=="noOB" && configNodeSel=="breadth") || 
           (p==4 && configOB=="noOB" && configNodeSel=="breadth") ||
           (p==5 && configOB=="noOB" && configNodeSel=="breadth"))

tst <- datMain
  
tst %>%
  group_by(pb, p, configLB) %>%
  arrange(cpuTotal) %>%
  mutate(count = row_number()) %>% 
    ggplot() +
    geom_step( aes(x = cpuTotal, y = count,color = configValSplit, linetype = configLB) ) +
    facet_wrap(vars(pb, p), scales = "free") +
    xlab("CPU time (in seconds)") + ylab("number of instances solved")
    #facet_grid(vars(pb), vars(p), scales = "free")
  
# from main expe

#dat %>%
#  group_by(pb, p, configLB) %>%
#  arrange(cpuTotal) %>%
#  mutate(count = row_number()) %>%
#    ggplot() +
#    geom_step( aes(x = cpuTotal, y = count, linetype = configLB) ) +
#    facet_grid(vars(pb), vars(p), scales = "free")
```

```{r, echo=FALSE}
# With all instances aggregated:

# from prelim 

#tst2 <- datPrelim %>% # tst is best config only LP and WLP for prelim expe
#  group_by(instance, configLB, configValSplit) %>%
#  mutate(cpu = min(cpuTotal)) %>%
#  filter(cpu == cpuTotal) %>%
#  mutate(cpt = row_number()) %>%
#  filter(cpt == 1)

#tst <- datPrelim %>%
#  filter((p==3 && configOB=="noOB" && configNodeSel=="breadth") || 
#           (p==4 && configOB=="noOB" && configNodeSel=="breadth") ||
#           (p==5 && configOB=="noOB" && configNodeSel=="breadth"))
#  
#tst %>%
#  filter(pb != "UFLP") %>%
#  group_by(p, configLB) %>%
#  arrange(cpuTotal) %>%
#  mutate(count = row_number()) %>% 
#    ggplot() +
#    geom_step( aes(x = cpuTotal, y = count,color = configValSplit, linetype = configLB) ) +
#    facet_wrap(vars(p), scales = "free") +
#    xlab("CPU time (in seconds)") + ylab("number of instances solved")
#    #facet_grid(vars(pb), vars(p), scales = "free")
  
# from main expe

#dat %>%
#  group_by(pb, p, configLB) %>%
#  arrange(cpuTotal) %>%
#  mutate(count = row_number()) %>%
#    ggplot() +
#    geom_step( aes(x = cpuTotal, y = count, linetype = configLB) ) +
#    facet_grid(vars(pb), vars(p), scales = "free")
```

How many instances were solved for each problem class, number of objectives and LB configuration?

```{r, echo=FALSE}
tb1 <- tst %>% # tst is best config only LP and WLP for prelim expe
  ungroup() %>%
  filter(configValSplit == "mofv") %>%
  select(instance, configLB, solved, cpuTotal, nbLpSolved, nbNodes, pb, p) %>%
  group_by(instance) %>%
  pivot_wider(names_from = configLB, values_from = c(solved, cpuTotal, nbLpSolved, nbNodes))

tb1 %>%
  group_by(pb) %>%
  summarise(count_solved_LP = sum(solved_LP), count_solved_WLP = sum(solved_WLP)) %>%
  ungroup() %>%
  pivot_longer(!pb, names_to = "configLB", values_to = "count") %>%
    ggplot(aes(x = pb, y = count, fill = configLB)) +
    geom_bar(stat = "identity", position = "dodge")
```


For the instances that were solved in both configurations, what is the average speed-up? In this table, we express how large the reduction of CPU time used is in the WLP configuration, compared to the LP configuration, expressed in percentages. For example, for the ILP instances with three objectives, the WLP configuration is in average $27.4\%$ faster compared to the LP configuration.

```{r, echo=FALSE}
#tb1 <- tst %>% # tst is best config only LP and WLP for prelim expe
#  ungroup() %>%
#  filter(configValSplit == "mofv") %>%
#  select(instance, configLB, solved, cpuTotal, nbLpSolved, nbNodes, pb, p) %>%
#  group_by(instance) %>%
#  pivot_wider(names_from = configLB, values_from = c(solved, cpuTotal, nbLpSolved, nbNodes))
  
tb1 %>%
  ungroup() %>%
  filter(solved_LP == 1, solved_WLP == 1) %>%
  group_by(pb, p) %>%
  summarise(avgSpeedup = 100 * (mean(cpuTotal_LP) - mean(cpuTotal_WLP)) / mean(cpuTotal_LP)) %>%
  ungroup() %>%
  pivot_wider(names_from = p, values_from = avgSpeedup) %>%
  kable()
  

```

Another point of view for the same statistic: the LP configuration takes x times more CPU time than the WLP configuration.

```{r, echo=FALSE}
tb1 %>%
  ungroup() %>%
  filter(solved_LP == 1, solved_WLP == 1) %>%
  group_by(pb, p) %>%
  summarise(avgSpeedup = mean(cpuTotal_LP) / mean(cpuTotal_WLP)) %>%
  ungroup() %>%
  pivot_wider(names_from = p, values_from = avgSpeedup) %>%
  kable()

```

How many calls to the single-objective LP solver were saved? In the LP config, we solved x times more LPs than in the WLP config.

```{r, echo=FALSE}
tb1 %>%
  ungroup() %>%
  filter(solved_LP == 1, solved_WLP == 1) %>%
  group_by(pb, p) %>%
  summarise(avgSpeedup = mean(nbLpSolved_LP) / mean(nbLpSolved_WLP)) %>%
  ungroup() %>%
  pivot_wider(names_from = p, values_from = avgSpeedup) %>%
  kable()

```

For instances that were unsolved in both LB configurations, how many more nodes were explored by the WLP configuration compared to the LP configuration? Unsolved instances have the particularity that both configurations were stopped at the same point in time. Hence we can compare how much progress was made in both cases. It is relevant to compare the tree size here because in both LB configuration, the tree is the same (same LB computed so same branching decisions made). Small variation can appear if alternative pre-image exists for some points of some LB in the tree, but in practice it appears to be a few nodes of difference. Note that this statistic does not answer to "how faster" one configuration is compared to the other, because nodes can take more cpu time depending on how deep they are in the BB tree.
Analysis: WLP configuration explored x times more nodes than LP configuration whithin the time limit (600 sec now, but 3600 are coming!).

```{r, echo=FALSE}
tb1 %>%
  ungroup() %>%
  filter(solved_LP == 0, solved_WLP == 0) %>%
  group_by(pb, p) %>%
  summarise(avgTreeSize = mean(nbNodes_WLP) / mean(nbNodes_LP)) %>%
  ungroup() %>%
  pivot_wider(names_from = p, values_from = avgTreeSize) %>%
  kable()

```

```{r, echo=FALSE}
#What is the average speedup in function of the number of variables and the number of objective for each problem class?
#jcp <- tst %>%
#  filter(solved == 1) %>%
#  group_by(instance) %>%
#  mutate(speedup = max(cpuTotal) / min(cpuTotal)) %>%
#  filter(speedup != 1) %>%
#  filter(configLB == "WLP")

#jcp %>%
#  group_by(pb, n, p) %>%
#  summarise(avgSpeedUp = mean(speedup)) %>%
#    ggplot() +
#    geom_line(aes(n, avgSpeedUp, color=factor(p))) +
#    facet_wrap(vars(pb), scales = "free")
```


```{r, echo=FALSE}

# How can we explain this results? First, let's have a look at where most of the cpu time is used during the algorithm.

#res <- dat %>% 
#  filter(solved == 1) %>%
#  mutate(pctLB = 100 * cpuLbComputation / cpuTotal , pctUB = 100 * cpuUbUpdate / cpuTotal , pctDomiTest = 100 * cpuDominanceTest / cpuTotal , pctNodeSel = 100 * cpuNodeSel / cpuTotal , pctVarSel = 100 * cpuVarSel / cpuTotal , pctOther = 100 - pctLB - pctUB - pctDomiTest - pctNodeSel - pctVarSel) %>%
#  group_by(p, n, configLB) %>% 
#  summarise(avgLB = mean(pctLB) , avgUB = mean(pctUB) , avgDomiTest = mean(pctDomiTest) , avgNodeSel = mean(pctNodeSel) , avgVarSel = mean(pctVarSel) , avgOther = mean(pctOther)) %>%
#  pivot_longer(!c(p,n,configLB) , names_to = "part" , values_to = "pctCpu" ) #%>%


#ggplot(res, aes(x = factor(configLB), y = pctCpu, fill = part)) +
#  geom_col(color = "black") +
#  geom_text(aes(label = round(pctCpu, 2)), colour="white", size=2.5,
#              position = position_stack(vjust = .5)) +
#  facet_grid( rows = vars(n) , cols = vars(p), margins = F, scales = "free") +
#  ylab("% of total cpu time") + xlab("n")

```


```{r, echo=FALSE}

#res <- dat %>% 
#  filter(solved == 1) %>%
#  mutate(pctCplex = 100 * cpuCplex / cpuLbComputation , pctUpdatePolyhedron = 100 * cpuUpdatePolyhedron / cpuLbComputation , pctInitialization = 100 * cpuInitialization / cpuLbComputation, pctOther = 100 - pctCplex - pctUpdatePolyhedron - pctInitialization) %>%
#  group_by(p, n, configLB) %>% 
#  summarise(avgCplex = mean(pctCplex) , avgUpdatePolyhedron = mean(pctUpdatePolyhedron) , avgInitialization = mean(pctInitialization) , avgOther = mean(pctOther)) %>%
#  pivot_longer(!c(p,n,configLB) , names_to = "part" , values_to = "pctCpu" ) #%>%

#ggplot(res, aes(x = factor(configLB), y = pctCpu, fill = part)) +
#  geom_col(color = "black") +
#  geom_text(aes(label = round(pctCpu, 2)), colour="white", size=2.5,
#              position = position_stack(vjust = .5)) +
#  facet_grid( rows = vars(n) , cols = vars(p), margins = F, scales = "free") +
#  ylab("% of total LB computation time") + xlab("n")
 #ggplot(res, aes(x = factor(n), y = pct, fill = OB, linetype = nodeselVarsel)) + 
#  geom_col(color = "black") + 
#  geom_text(aes(label = round(pct, 2)), colour="white", size=2.5,
#              position = position_stack(vjust = .5)) +
#  scale_fill_ob + scale_linetype_nodesel_varsel +
#  facet_grid(cols = vars(pb), margins = F, scales = "free") +
#  ylab("% of instances") + xlab("n") +
#  theme_publish()
```


```{r, echo=FALSE}

# prelim expe

#intr <- tst %>%
#  group_by(instance) %>%
#  mutate(allSolved = min(solved)) %>%
#  filter(allSolved == 1) %>%
#  mutate(reductionRelative = 100 - 100*nbLpSolved/max(nbLpSolved))

#intr %>%
#  group_by(pb,p,n,configLB) %>%
#  summarise(avgLpSolved = mean(reductionRelative)) %>% # nbLpSolved
#  ggplot() +
#  geom_line( aes(n,avgLpSolved,color=configLB,linetype = configLB) ) +
#  facet_wrap(vars(pb,p), scales = "free_x") +
#    xlab("number of variables (n)") + ylab("relative reduction of calls to the single-objective LP solver")

# main expe

#dat %>%
#  filter(solved == 1) %>%
#  group_by(pb,p,n,configLB) %>%
#  summarise(avgLpSolved = mean(nbLpSolved)) %>%
#  ggplot() +
#  geom_line( aes(n,avgLpSolved,linetype = configLB) ) +
#  facet_grid(vars(pb), vars(p), scales = "free")
```


# Others

Number of non-dominated points. There is a plot for each problem (ILP, PPP, UFLP) and number of objectives (3, 4, 5).
Note : only instances with at least one congiguration solved is kept. Hence the number of non-dominated points may appear lower than it is in reality for the hardest instances.


```{r, echo=FALSE}

datPrelim %>%
  filter(solved == 1) %>%
  group_by(instance) %>%
  mutate(mini = min(cpuTotal)) %>%
  filter(mini == cpuTotal) %>%
    ggplot() +
    geom_boxplot(aes(factor(n),YN, group = factor(n))) +
    facet_wrap(vars(pb,p), scales = "free_x") +
    xlab("number of variables (n)") + ylab("|YN|")

#res <- dat %>%
#  filter(solved == 1) %>%
#  group_by(p,n) %>%
#  summarise(avgYn = mean(YN))
  
#res %>% ggplot() +
#  geom_point( data = dat, aes(n,YN,col = factor(p)) ) +
#    geom_line( aes(n,avgYn,col = factor(p)) )
```

# Results without OB

For node seletion. Aggregated results

```{r, echo = FALSE}
datPrelim %>%
  filter(configOB == "noOB") %>%
  group_by(p, configLB, configNodeSel) %>%
  arrange(cpuTotal) %>%
  mutate(count = row_number()) %>%
    ggplot() +
    geom_step(aes(x = cpuTotal, y = count, color = configNodeSel)) +
    facet_grid(vars(p), vars(configLB), scales = "free") +
    xlab("CPU time (in seconds)") + ylab("number of instances solved")


```

For warmstarting.

```{r, echo=FALSE}
# from prelim 

datPrelim %>%
  filter(configOB == "noOB") %>%
  group_by(pb, p, configLB, configNodeSel) %>%
  arrange(cpuTotal) %>%
  mutate(count = row_number()) %>% 
    ggplot() +
    geom_step( aes(x = cpuTotal, y = count,color = configNodeSel, linetype = configLB) ) +
    facet_wrap(vars(pb, p), scales = "free") +
    xlab("CPU time (in seconds)") + ylab("number of instances solved")
    #facet_grid(vars(pb), vars(p), scales = "free")
  
# from main expe

#dat %>%
#  group_by(pb, p, configLB) %>%
#  arrange(cpuTotal) %>%
#  mutate(count = row_number()) %>%
#    ggplot() +
#    geom_step( aes(x = cpuTotal, y = count, linetype = configLB) ) +
#    facet_grid(vars(pb), vars(p), scales = "free")
```

# Further preliminary study on OB

## ILP

```{r, echo = FALSE}
datPrelim %>%
  filter(pb == "ILP") %>%
  group_by(p, configLB, configOB, configNodeSel) %>%
  arrange(cpuTotal) %>%
  mutate(count = row_number()) %>%
    ggplot() +
    geom_step(aes(x = cpuTotal, y = count, color = configNodeSel, linetype = configLB)) +
    facet_grid(vars(p), vars(configOB), scales = "free") +
    xlab("CPU time (in seconds)") + ylab("number of instances solved")


```

## UFLP

```{r, echo = FALSE}
datPrelim %>%
  filter(pb == "UFLP") %>%
  group_by(p, configLB, configOB, configNodeSel) %>%
  arrange(cpuTotal) %>%
  mutate(count = row_number()) %>%
    ggplot() +
    geom_step(aes(x = cpuTotal, y = count, color = configNodeSel, linetype = configLB)) +
    facet_grid(vars(p), vars(configOB), scales = "free") +
    xlab("CPU time (in seconds)") + ylab("number of instances solved")


```

## PPP

```{r, echo = FALSE}
datPrelim %>%
  filter(pb == "PPP") %>%
  group_by(p, configLB, configOB, configNodeSel) %>%
  arrange(cpuTotal) %>%
  mutate(count = row_number()) %>%
    ggplot() +
    geom_step(aes(x = cpuTotal, y = count, color = configNodeSel, linetype = configLB)) +
    facet_grid(vars(p), vars(configOB), scales = "free") +
    xlab("CPU time (in seconds)") + ylab("number of instances solved")


```


